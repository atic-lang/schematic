use atic.schematic.Atic;
use atic.schematic.tokens.Tokenizer;
use atic.schematic.tokens.TokenStream;


fn generateRuleSet(lines: List<string>) -> RuleSet {
    let resolves: List<fn() -> void> = newList<fn() -> void>();
    let tokens: List<Token> = genReaderTokens();
    let rules: List<Rule> = newList<Rule>();

    let lineCount: Ref<number> = Ref(0);
    forEach(lines, fn (line: string) -> void {
        let lineCounter: number = lineCount.value;
        let result: List<TokenRecord> = generateTokens(tokens,line,lineCounter);
        lineCount.value = lineCount.value + 1;

        let filtered: List<TokenRecord> = filter(result, fn (token: TokenRecord) -> bool {
            if token.token.alias == "whitespace" return false;
            else return true;
        });


        let stream: TokenStream<TokenRecord> = generateTokenStream(filtered);
        if filtered.size == 0 {
            return;
        }
        if testToken(stream, "comment") {
            return;
        }

        resolves;
        rules;
        let rule: Rule = genRule(stream, fn (name: string, ref: Entry) -> void {
            let name_ = name;
            let ref_ = ref;
            rules;
            let f: fn() -> void = fn () -> void {
                 let found: Rule = findByName(rules,name_);
                 ref_.rule = Optional.Some(found);
            };
            insert(resolves,f);
        });

        insert(rules,rule);

    });
    forEach(resolves,fn (func: fn() -> void) -> void {
        func();
    });

    return RuleSet(rules);
}



fn genRule(stream: TokenStream<TokenRecord>, callback:  fn (string, Entry) -> void) -> Rule {
    let sentences: List<Sentence> = newList<Sentence>();

    let name: string = assertToken(stream,"keyword");
   // print("Name: " + name);
    consume(stream);
    assertToken(stream,"assign");

    consume(stream);
    while hasEntriesLeft(stream) {
        let entries: List<Entry> = newList<Entry>();
        while hasEntriesLeft(stream) && !testToken(stream, "or") {
            let data: string = current(stream).data;
            if testToken(stream, "keyword") {
                let e: Entry = Entry("",Optional.None<Rule>(),false,false);
                insert(entries,e);
                callback(data,e);
                consume(stream);
                if hasEntriesLeft(stream) && testToken(stream, "concrete") {
                    consume(stream);
                    e.isConcrete = true;
                }

            } else if testToken(stream, "literal") {
                let subStr: string = substring2(data,1, length(data) - 1);
                let e: Entry = Entry(subStr,Optional.None<Rule>(),false,false);
                insert(entries,e);
                consume(stream);
                if hasEntriesLeft(stream) && testToken(stream, "hidden") {
                    consume(stream);
                    e.isHidden = true;
                }

                 if hasEntriesLeft(stream) && testToken(stream, "concrete") {
                    consume(stream);
                    e.isConcrete = true;
                 }


            } else {
                throw NotFoundMsgError("expected literal or keyword");
            }
        }
        consume(stream);
        insert(sentences,Sentence(entries));
    }
    return Rule(name,sentences);
}



fn testToken(stream: TokenStream<TokenRecord>, type: string) -> bool {
    if !hasEntriesLeft(stream) {
            //throw AssertError("stream has nothing left when testing");
        return false;
    }
    let current_: TokenRecord = current(stream);
    return current_.token.alias == type;
}

fn assertToken(stream: TokenStream<TokenRecord>, type: string) -> string {
    if !hasEntriesLeft(stream) {
        throw AssertError("stream has nothing left");
    }
    let current_: TokenRecord = current(stream);
    if current_.token.alias != type {
       throw AssertError("Expected " + type + ", but got " + current_.token.alias);
    }
    return current_.data;
}

struct RuleSet {
    rules: List<Rule>;
}

struct Rule {
    name: string;
    sentences: List<Sentence>;
}

struct Sentence {
    entries: List<Entry>;
}

struct Entry {
    literal: string;
    rule: Optional<Rule>;
    isHidden: bool;
    isConcrete: bool;
}

fn findByName(list: List<Rule>, name: string) -> Rule {
     let i: number = 0;
     let s: number = list.size;

     while i < s {
         let element: Rule = getAt(list,i);
         if ignoreCase(element.name, name) {
            return element;
         }
         i = i + 1;
     }

    throw NotFoundMsgError("cant find " + name);
}

fn genReaderTokens() -> List<Token> {
    let list: List<Token> = newList<Token>();

    let keyword: Token = genToken("keyword","[a-zA-Z]", "\\w+$");
    let whitespace: Token = genToken("whitespace","\\s", "\\s*");
    let assign: Token = genToken("assign",":=", "(:|:=)");
    let literal: Token = genToken("literal","\"", "((\\\"[^\\\"]*\\\")|(\\\"[^\\\"]*))");
    let or: Token = genToken("or","\\|", "\\|");
    let hidden: Token = genToken("hidden","\\?", "\\?");
    let concrete: Token = genToken("concrete","\\!", "\\!");
    let comment: Token = genToken("comment","//", "//.*");

    insert(list,keyword);
    insert(list,whitespace);
    insert(list,assign);
    insert(list,literal);
    insert(list,or);
    insert(list,hidden);
    insert(list,concrete);
    insert(list,comment);

    return list;
}
